{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import numpy as np \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Creation: Create a 2D tensor of size (4, 5) with random integers ranging from 0 to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.randint(low, high, size): Creates a tensor filled with random integers from low (inclusive) to high (exclusive).\n",
    "#0 is the lower bound (inclusive).\n",
    "#51 is the upper bound (exclusive) to include numbers up to 50.\n",
    "#(4, 5) specifies the desired shape of the tensor.\n",
    "tensor1=torch.randint(0,51,(4,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Reshaping: Given a tensor of size (3, 4, 2), reshape it to a tensor of size (2, 3, 4). Verify the total number of elements remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements same in number.\n"
     ]
    }
   ],
   "source": [
    "# tensor creation\n",
    "tensor2=torch.randint(0,51,(3,4,2))\n",
    "#tensor reshaping \n",
    "tensor2_reshaped=tensor2.reshape(2,3,4)\n",
    "\n",
    "#getting number of elements in tensor2 and reshaped tensor using .numel \n",
    "#The .numel() method in PyTorch is used to calculate the total number of elements in a tensor.\n",
    "ntensor2=tensor2.numel()\n",
    "ntensor2reshaped=tensor2_reshaped.numel()\n",
    "if ntensor2 ==ntensor2reshaped: \n",
    "    print(\"Elements same in number.\")\n",
    "else: \n",
    "    print(\"Shata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Information: Create a 3D tensor of size (2, 3, 4). Write a function that takes any tensor as input and returns its number of dimensions, shape, and total number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 torch.Size([2, 3, 4]) 24\n"
     ]
    }
   ],
   "source": [
    "def tensor_info(tensor):\n",
    "    dim=tensor.ndim\n",
    "    shape=tensor.shape\n",
    "    nele=tensor.numel() \n",
    "    return dim,shape,nele\n",
    "\n",
    "dimension,shape,nelements=tensor_info(tensor2_reshaped)\n",
    "print(dimension,shape,nelements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar Operations: Create a tensor of size (5, 5) filled with the value 10. Multiply each element of this tensor by 0.5, then add 5 to each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8, 0, 5, 3, 3],\n",
      "        [3, 2, 7, 0, 5],\n",
      "        [8, 7, 8, 4, 1],\n",
      "        [7, 4, 1, 7, 2],\n",
      "        [5, 1, 9, 0, 2]])\n",
      "tensor([[4.0000, 0.0000, 2.5000, 1.5000, 1.5000],\n",
      "        [1.5000, 1.0000, 3.5000, 0.0000, 2.5000],\n",
      "        [4.0000, 3.5000, 4.0000, 2.0000, 0.5000],\n",
      "        [3.5000, 2.0000, 0.5000, 3.5000, 1.0000],\n",
      "        [2.5000, 0.5000, 4.5000, 0.0000, 1.0000]])\n",
      "tensor([[9.0000, 5.0000, 7.5000, 6.5000, 6.5000],\n",
      "        [6.5000, 6.0000, 8.5000, 5.0000, 7.5000],\n",
      "        [9.0000, 8.5000, 9.0000, 7.0000, 5.5000],\n",
      "        [8.5000, 7.0000, 5.5000, 8.5000, 6.0000],\n",
      "        [7.5000, 5.5000, 9.5000, 5.0000, 6.0000]])\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.randint(0,10,(5,5))\n",
    "print(tensor)\n",
    "tensormul=tensor.mul(0.5)\n",
    "print(tensormul)\n",
    "tensorsum=tensormul+5\n",
    "print(tensorsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication: Create two tensors of size (3, 4) and (4, 2). Perform matrix multiplication between them. Verify the resulting tensor's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13, 20],\n",
      "        [10, 22],\n",
      "        [13, 22]])\n"
     ]
    }
   ],
   "source": [
    "tens1=torch.randint(0,5,(3,4))\n",
    "tens2=torch.randint(0,5,(4,2))\n",
    "matmul=tens1@tens2\n",
    "print(matmul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Element-wise Operations: Create two tensors of the same size (4, 4) with random values. Perform element-wise addition, subtraction, multiplication, and division between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 0, 1, 3],\n",
      "        [0, 1, 3, 1],\n",
      "        [3, 0, 4, 4],\n",
      "        [2, 0, 2, 4]])\n",
      "tensor([[9, 7, 8, 8],\n",
      "        [9, 7, 7, 5],\n",
      "        [7, 7, 8, 6],\n",
      "        [8, 6, 9, 6]])\n",
      "tensor([[12,  7,  9, 11],\n",
      "        [ 9,  8, 10,  6],\n",
      "        [10,  7, 12, 10],\n",
      "        [10,  6, 11, 10]])\n",
      "tensor([[-6, -7, -7, -5],\n",
      "        [-9, -6, -4, -4],\n",
      "        [-4, -7, -4, -2],\n",
      "        [-6, -6, -7, -2]])\n",
      "tensor([[27,  0,  8, 24],\n",
      "        [ 0,  7, 21,  5],\n",
      "        [21,  0, 32, 24],\n",
      "        [16,  0, 18, 24]])\n",
      "tensor([[0.3333, 0.0000, 0.1250, 0.3750],\n",
      "        [0.0000, 0.1429, 0.4286, 0.2000],\n",
      "        [0.4286, 0.0000, 0.5000, 0.6667],\n",
      "        [0.2500, 0.0000, 0.2222, 0.6667]])\n"
     ]
    }
   ],
   "source": [
    "tens1=torch.randint(0,5,(4,4))\n",
    "print(tens1)\n",
    "tens2=torch.randint(5,10,(4,4))\n",
    "print(tens2)\n",
    "print(tens1 + tens2)\n",
    "\n",
    "print(tens1 - tens2)\n",
    "\n",
    "print(tens1 * tens2)\n",
    "\n",
    "print(tens1 / tens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing: Create a 3D tensor of size (4, 3, 2). Extract the tensor formed by the first 2 rows of the second dimension for all elements in the other dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element at (2, 3): tensor(12)\n",
      "Second row: tensor([5, 6, 7, 8])\n",
      "Third column: tensor([ 3,  7, 11, 15])\n",
      "Sub-tensor (2x2):\n",
      "tensor([[ 6,  7],\n",
      "        [10, 11]])\n"
     ]
    }
   ],
   "source": [
    "#indexing basics\n",
    "\n",
    "# Create a 2D tensor (4x4)\n",
    "tensor_2d = torch.tensor([[1, 2, 3, 4],\n",
    "                          [5, 6, 7, 8],\n",
    "                          [9, 10, 11, 12],\n",
    "                          [13, 14, 15, 16]])\n",
    "\n",
    "# Access a specific element\n",
    "element = tensor_2d[2, 3]  # Access the element in the 3rd row and 4th column\n",
    "print(\"Element at (2, 3):\", element)\n",
    "\n",
    "# Access an entire row\n",
    "row = tensor_2d[1, :]  # Access the 2nd row\n",
    "print(\"Second row:\", row)\n",
    "\n",
    "# Access an entire column\n",
    "column = tensor_2d[:, 2]  # Access the 3rd column\n",
    "print(\"Third column:\", column)\n",
    "\n",
    "# Access a sub-tensor (slicing)\n",
    "sub_tensor = tensor_2d[1:3, 1:3]  # Access the 2x2 sub-matrix\n",
    "print(\"Sub-tensor (2x2):\")\n",
    "print(sub_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3, 0],\n",
      "         [1, 2],\n",
      "         [4, 1]],\n",
      "\n",
      "        [[3, 0],\n",
      "         [1, 0],\n",
      "         [3, 0]],\n",
      "\n",
      "        [[3, 0],\n",
      "         [2, 3],\n",
      "         [4, 2]],\n",
      "\n",
      "        [[0, 2],\n",
      "         [3, 4],\n",
      "         [2, 1]]])\n"
     ]
    }
   ],
   "source": [
    "#inedexing 3d tesnors \n",
    "'''\n",
    "A 3D tensor can be visualized as a stack of matrices (2D tensors). Indexing involves specifying indices for three dimensions: [depth, row, column].\n",
    "\n",
    "A 3D tensor can be thought of as a collection of 2D matrices stacked together, similar to how pages in a book are stacked. This stacking introduces an additional dimension, often called the depth or channel dimension, depending on the context.\n",
    "\n",
    "How 3D Tensors Are Arranged\n",
    "A 3D tensor in PyTorch has three dimensions that can be generalized as:\n",
    "\n",
    "Depth (Channel/Stack) - This is the first dimension, representing the number of 2D matrices (slices) in the stack. Each slice is a 2D matrix.\n",
    "Rows - The second dimension represents the number of rows in each 2D matrix.\n",
    "Columns - The third dimension represents the number of columns in each 2D matrix.\n",
    "\n",
    "import torch\n",
    "\n",
    "# Creating a 3D tensor of size (2, 3, 4)\n",
    "tensor_3d = torch.tensor([\n",
    "    [\n",
    "        [1, 2, 3, 4],\n",
    "        [5, 6, 7, 8],\n",
    "        [9, 10, 11, 12]\n",
    "    ],\n",
    "    [\n",
    "        [13, 14, 15, 16],\n",
    "        [17, 18, 19, 20],\n",
    "        [21, 22, 23, 24]\n",
    "    ]\n",
    "])\n",
    "\n",
    "print(tensor_3d.shape)  # Output: torch.Size([2, 3, 4])\n",
    "\n",
    "\n",
    "Accessing Elements in a 3D Tensor\n",
    "To access elements in a 3D tensor, you use three indices: [depth, row, column].\n",
    "\n",
    "Example: Access Specific Elements\n",
    "tensor_3d[0, 1, 2] accesses the element in the 1st slice, 2nd row, and 3rd column. In this case, it would be 7.\n",
    "tensor_3d[1, 2, 3] accesses the element in the 2nd slice, 3rd row, and 4th column. In this case, it would be 24.\n",
    "\n",
    "General Indexing Rules\n",
    "Single Colon (:): Selects all elements along that dimension.\n",
    "Slicing (start:stop:step): Similar to Python lists, can select a range of elements along a dimension.\n",
    "Ellipsis (...): Can be used to select all elements of unspecified dimensions, e.g., tensor[..., 2] selects the 3rd element in the\n",
    " last dimension across all others.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "tens1=torch.randint(0,5,(4,3,2))\n",
    "print(tens1)\n",
    "\n",
    "#Extract the tensor formed by the first 2 rows of the second dimension for all elements in the other dimensions.\n",
    "accesstensor=tens1[:,:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing: Given a tensor of shape (6, 6), slice out the center 2x2 block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3],\n",
      "        [2, 3]])\n"
     ]
    }
   ],
   "source": [
    "tens=torch.randint(0,5,(6,6))\n",
    "slicedtens=tens[2:4,2:4]\n",
    "print(slicedtens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Selection: Create a tensor of size (4, 4) with random values. Replace all elements greater than 0.5 with 1, and all elements less than or equal to 0.5 with 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2692, 0.8762, 0.3002, 0.3975],\n",
      "        [0.3956, 0.7803, 0.0890, 0.5810],\n",
      "        [0.1771, 0.6984, 0.4115, 0.1997],\n",
      "        [0.6817, 0.6739, 0.0596, 0.5322]])\n",
      "tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "torch.where(condition, x, y):\n",
    "Takes three arguments: a condition, x, and y.\n",
    "Condition:  creates a boolean mask where each element is checked if it's greater than 0.5.\n",
    "x: Value to replace where the condition is True (1 in this case).\n",
    "y: Value to replace where the condition is False (0 in this case).\n",
    "\n",
    "'''\n",
    "\n",
    "tenss=torch.rand(4,4)\n",
    "print(tenss)\n",
    "tenss=tenss.where(tenss>0.5,0)\n",
    "tenss=tenss.where(tenss<0.5,1)\n",
    "print(tenss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking: Create two 1D tensors of size 5 each. Stack them vertically and horizontally to form a 2D tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking: Create two 1D tensors of size 5 each. Stack them vertically and horizontally to form a 2D tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 1-dimensional tensor of size 5 with random integers between 0 and 10\n",
    "#tensor_1d = torch.randint(0, 10, (5,))\n",
    "#torch.randint(low, high, size):\n",
    "#low: The lower bound (inclusive) for random values.\n",
    "#high: The upper bound (exclusive) for random values.\n",
    "#size: The shape of the tensor. (5,) indicates a 1-dimensional tensor with 5 elements.\n",
    "\n",
    "tensor1 = torch.tensor([1, 2, 3, 4, 5])\n",
    "tensor2 = torch.tensor([6, 7, 8, 9, 10])\n",
    "\n",
    "'''\n",
    "torch.stack()\n",
    "What It Does:\n",
    "torch.stack() joins a sequence of tensors along a new dimension. This new dimension is specified by the dim parameter.\n",
    "Unlike concatenation (torch.cat()), which joins tensors along an existing dimension, torch.stack() adds a new dimension,\n",
    " effectively \"stacking\" the tensors on top of each other.\n",
    "\n",
    "Arguments:\n",
    "tensors: A sequence (list or tuple) of tensors that you want to stack.\n",
    "dim: The dimension along which to insert the new dimension. This argument is an integer, and it can range from 0 to the number \n",
    "of dimensions of the tensors.\n",
    "\n",
    "\n",
    "Requirements:\n",
    "All tensors in the input sequence must have the same shape.\n",
    "\n",
    "torch.vstack()\n",
    "What It Does:\n",
    "torch.vstack() vertically stacks tensors (i.e., stacks them along the first dimension). It is similar to concatenating tensors \n",
    "along the rows.\n",
    "It's equivalent to using torch.cat(tensors, dim=0) for 2D tensors.\n",
    "\n",
    "Arguments:\n",
    "tensors: A sequence of tensors to stack vertically.\n",
    "\n",
    "Requirements:\n",
    "The tensors must have the same number of columns (i.e., the same shape except in the first dimension).\n",
    "\n",
    "\n",
    "torch.hstack()\n",
    "What It Does:\n",
    "torch.hstack() horizontally stacks tensors (i.e., stacks them along the second dimension). It is similar to concatenating tensors\n",
    " along the columns.\n",
    "It’s equivalent to using torch.cat(tensors, dim=1) for 2D tensors.\n",
    "\n",
    "Arguments:\n",
    "tensors: A sequence of tensors to stack horizontally.\n",
    "\n",
    "Requirements:\n",
    "The tensors must have the same number of rows (i.e., the same shape except in the last dimension).\n",
    "\n",
    "\n",
    "Differences Between Them\n",
    "torch.stack():\n",
    "Creates a new dimension to stack the tensors.\n",
    "Requires specifying which dimension to insert (dim).\n",
    "The input tensors must have the same shape.\n",
    "torch.vstack():\n",
    "Stacks tensors along the vertical axis (first dimension, like stacking rows).\n",
    "Equivalent to torch.cat(tensors, dim=0) for 2D tensors.\n",
    "Input tensors must have the same number of columns.\n",
    "torch.hstack():\n",
    "Stacks tensors along the horizontal axis (second dimension, like stacking columns).\n",
    "Equivalent to torch.cat(tensors, dim=1) for 2D tensors.\n",
    "Input tensors must have the same number of rows.\n",
    "\n",
    "'''\n",
    "\n",
    "stackedtensor=torch.stack((tensor1,tensor2),0)\n",
    "print(stackedtensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting: Given a tensor of size (8, 8), split it into four smaller tensors of size (4, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Splitting a tensor means dividing a larger tensor into smaller sub-tensors along a specified dimension. This can be useful \n",
    "when processing data in chunks, applying operations to specific segments of data, or simply organizing data into more manageable\n",
    " pieces.\n",
    "\n",
    "How to Split Tensors in PyTorch\n",
    "PyTorch provides multiple functions to split tensors:\n",
    "\n",
    "torch.split(): Splits a tensor into chunks of specified size(s) along a given dimension.\n",
    "torch.chunk(): Divides a tensor into a specified number of equal-sized chunks along a given dimension.\n",
    "1. Using torch.split()\n",
    "torch.split(tensor, split_size_or_sections, dim=0):\n",
    "tensor: The tensor to split.\n",
    "split_size_or_sections: Specifies the size of each chunk or a list defining the sizes of each chunk.\n",
    "dim: The dimension along which to split the tensor\n",
    "\n",
    "\n",
    "2.Using torch.chunk()\n",
    "torch.chunk(tensor, chunks, dim=0):\n",
    "tensor: The tensor to split.\n",
    "chunks: The number of chunks to split the tensor into.\n",
    "dim: The dimension along which to split the tensor.\n",
    "\n",
    "Where is Tensor Splitting Used?\n",
    "Batch Processing: Splitting large batches of data into smaller batches for processing in neural networks.\n",
    "Data Sharding: When working with distributed systems or parallel processing, data is split into smaller shards.\n",
    "Cross-Validation: In machine learning, splitting data into folds for cross-validation.\n",
    "Memory Management: To avoid memory overflow, large tensors are split into smaller ones that can be processed sequentially.\n",
    "Chunk-wise Operations: Applying operations or functions to specific segments of data, such as processing different parts of an \n",
    "image separately.\n",
    "Summary of Differences Between torch.split() and torch.chunk()\n",
    "torch.split():\n",
    "More flexible since you can specify the exact size of each chunk.\n",
    "Can take a list of sizes, allowing non-uniform splitting.\n",
    "torch.chunk():\n",
    "Splits the tensor into a specific number of equal chunks.\n",
    "If the size of the tensor is not perfectly divisible by the number of chunks, some chunks may be smaller than others.\n",
    "Example for Clarity\n",
    "torch.split(tensor, 2) splits into chunks of size 2.\n",
    "torch.chunk(tensor, 4) splits the tensor into 4 equal-sized chunks.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting: Create a tensor of shape (2, 3) and a 1D tensor of size 3. Add them together using broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transpose: Create a tensor of size (3, 4). Swap its rows and columns using transpose, resulting in a tensor of size (4, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation: Create three tensors of size (3, 2). Concatenate them along the rows (first dimension) and columns (second dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flattening: Given a 4D tensor of size (2, 3, 4, 5), flatten it to a 1D tensor. Verify the total number of elements is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can also find the index of a tensor where the max or minimum occurs with torch.argmax() and torch.argmin() respectively.\n",
    "\n",
    "This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself (we'll see this in a later section when using the softmax activation function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.argmax()\n",
    "What it does: Returns the index of the maximum value in a tensor. If you specify a dimension (or axis), it finds the index of the maximum value along that dimension.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "input: The input tensor where the maximum values are to be found.\n",
    "\n",
    "dim (optional): The dimension along which to find the maximum. If not provided, it returns the index of the maximum element in the flattened tensor.\n",
    "\n",
    "keepdim (optional): If set to True, the output tensor retains the reduced dimension with size 1. Default is False.\n",
    "\n",
    "# torch.argmin()\n",
    "What it does: Returns the index of the minimum value in a tensor. Similar to argmax, it can return the index of the minimum value along a specified dimension or in the flattened tensor.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "input: The input tensor where the minimum values are to be found.\n",
    "\n",
    "dim (optional): The dimension along which to find the minimum. If not provided, it returns the index of the minimum element in the flattened tensor.\n",
    "\n",
    "keepdim (optional): If set to True, the output tensor retains the reduced dimension with size 1. Default is False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# you can directly call the argmax or argmin methods on a tensor object.\n",
    "#  For example, if you have a tensor named tensor, you can use:\n",
    "\n",
    "result_max = tensor.argmax()  # Calls the method on the tensor\n",
    "result_min = tensor.argmin()  # Calls the method on the tensor\n",
    "print(result_max)\n",
    "print(result_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducability(Trying to take the random out of random)\n",
    "In short how a neural network works start with random number -> tensor operations > update random numbers to try and make them better representations of the data -> again -> again -> again ...\n",
    "\n",
    "PyTorch's rand() method, generated a random tensor for the given input dimension everytime. To reduce the randomness in neural networks and PyTorch comes the concept of a random seed.\n",
    "\n",
    "Essentially what the random seed does is \"flavour the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8464, 0.2895, 0.4066, 0.5553],\n",
      "        [0.6870, 0.8075, 0.3077, 0.4079],\n",
      "        [0.6756, 0.2788, 0.9416, 0.7814]])\n",
      "tensor([[2.0311e-01, 4.8787e-02, 7.2849e-04, 4.2267e-01],\n",
      "        [6.5901e-01, 8.3514e-01, 6.3753e-01, 9.9646e-01],\n",
      "        [3.3878e-01, 4.2426e-01, 7.4976e-01, 2.2712e-01]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Create two random tensors\n",
    "\n",
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# we make the above tensors reproducable ,as follows\n",
    "\n",
    "import torch\n",
    "\n",
    "# set the random sees, commonly used value is 42\n",
    "# You can set it to any number\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A seed in the context of random number generation is an initial value that initializes a pseudo-random number generator (PRNG). PRNGs are algorithms that generate sequences of numbers that appear random but are actually deterministic, meaning that if you know the seed, you can predict the sequence. The seed value ensures that the sequence of \"random\" numbers is reproducible.\n",
    "\n",
    "When you set a seed, you are essentially telling the random number generator to start at a specific point in its number generation process. This allows for reproducibility in experiments and code execution. If you run the same code multiple times with the same seed, you'll get the same sequence of random numbers every time, which is essential in many fields like machine learning and simulations for debugging and consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running tensors and PyTorch objects on a GPU (Graphics Processing Unit) can significantly speed up computations, especially for large-scale deep learning tasks like training neural networks. This is because GPUs are optimized for parallel processing, which is highly beneficial when performing operations on large tensors or during matrix multiplications involved in deep learning.\n",
    "\n",
    "# Why Run PyTorch Tensors on a GPU?\n",
    "Speed: GPUs are highly efficient at performing many simple, similar operations in parallel. This makes them much faster for deep learning tasks and operations on large tensors compared to a CPU (which performs operations in a more sequential manner).\n",
    "\n",
    "Efficient for Deep Learning: Deep learning models involve large amounts of matrix operations (like tensor multiplications and additions). GPUs can handle these operations much faster due to their ability to parallelize computations.\n",
    "\n",
    "Massive Data Parallelism: The ability to handle thousands of parallel threads makes GPUs ideal for tasks that can be broken down into smaller independent units of work, like deep learning.\n",
    "\n",
    "# How to Run Tensors and PyTorch Objects on a GPU?\n",
    "PyTorch makes it easy to move tensors and models between the CPU and GPU. Below are the steps to do this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Checking GPU Availability:\n",
    "Before you can run your tensors on a GPU, you should check if a GPU is available on your machine:\n",
    "'''\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "'''\n",
    "If the output is True, then you have a CUDA-enabled GPU available for use. If it returns False, PyTorch will continue using the \n",
    "CPU for computations.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Tensors to a GPU:\n",
    "#To move a tensor to the GPU, you need to specify that the tensor should be stored on the GPU using the .to() or .cuda() method. \n",
    "cpu_tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Move the tensor to GPU\n",
    "gpu_tensor = cpu_tensor.to('cuda')\n",
    "# Or alternatively using .cuda()\n",
    "gpu_tensor = cpu_tensor.cuda()\n",
    "\n",
    "#Moves the tensor to the default GPU (if you have multiple GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Creating a Tensor Directly on the GPU:\n",
    "You can create a tensor directly on the GPU by specifying the device parameter when creating the tensor:\n",
    "'''\n",
    "gpu_tensor = torch.tensor([1, 2, 3], device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving a Model to the GPU:\n",
    "#When training a neural network, it's important to move both the model and data to the GPU. You can do this for a model using the \n",
    "# .to('cuda') method.\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "# Move the model to GPU\n",
    "model = model.to('cuda')\n",
    "input_tensor = torch.randn(10, 3).to('cuda')\n",
    "\n",
    "# Forward pass (runs on GPU)\n",
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Moving Tensors Back to the CPU:\n",
    "After performing computations on the GPU, you might want to move the results back to the CPU for further processing or to save \n",
    "memory on the GPU.\n",
    "\n",
    "# Move the tensor back to CPU\n",
    "cpu_tensor = gpu_tensor.to('cpu')\n",
    "print(cpu_tensor)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
